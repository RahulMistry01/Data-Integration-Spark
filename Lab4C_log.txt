/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/sbin/start-master.sh
starting org.apache.spark.deploy.master.Master, logging to /storage/work/rbm5518/Lab4/spark-rbm5518-org.apache.spark.deploy.master.Master-1-p-bc-5038.out
/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/bin/spark-class org.apache.spark.deploy.worker.Worker --work-dir /storage/work/rbm5518/Lab4 spark://p-bc-5038:7077
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/02/05 13:02:34 INFO Worker: Started daemon with process name: 2057533@p-bc-5038
25/02/05 13:02:34 INFO SignalUtils: Registering signal handler for TERM
25/02/05 13:02:34 INFO SignalUtils: Registering signal handler for HUP
25/02/05 13:02:34 INFO SignalUtils: Registering signal handler for INT
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/02/05 13:02:35 INFO Worker: Started daemon with process name: 3233168@p-bc-5040
25/02/05 13:02:35 INFO SignalUtils: Registering signal handler for TERM
25/02/05 13:02:35 INFO SignalUtils: Registering signal handler for HUP
25/02/05 13:02:35 INFO SignalUtils: Registering signal handler for INT
25/02/05 13:02:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/05 13:02:35 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:35 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:35 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:35 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/02/05 13:02:36 INFO Worker: Started daemon with process name: 3032823@p-bc-5089
25/02/05 13:02:36 INFO SignalUtils: Registering signal handler for TERM
25/02/05 13:02:36 INFO SignalUtils: Registering signal handler for HUP
25/02/05 13:02:36 INFO SignalUtils: Registering signal handler for INT
25/02/05 13:02:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/05 13:02:36 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:36 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:36 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:36 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:36 INFO Utils: Successfully started service 'sparkWorker' on port 33517.
25/02/05 13:02:36 INFO Worker: Worker decommissioning not enabled.
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/02/05 13:02:36 INFO Worker: Started daemon with process name: 851898@p-bc-5087
25/02/05 13:02:36 INFO SignalUtils: Registering signal handler for TERM
25/02/05 13:02:36 INFO SignalUtils: Registering signal handler for HUP
25/02/05 13:02:36 INFO SignalUtils: Registering signal handler for INT
25/02/05 13:02:36 INFO Worker: Starting Spark worker 10.6.8.48:33517 with 1 cores, 15.0 GiB RAM
25/02/05 13:02:36 INFO Worker: Running Spark version 3.3.0
25/02/05 13:02:36 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/02/05 13:02:36 INFO ResourceUtils: ==============================================================
25/02/05 13:02:36 INFO ResourceUtils: No custom resources configured for spark.worker.
25/02/05 13:02:36 INFO ResourceUtils: ==============================================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/02/05 13:02:36 INFO Worker: Started daemon with process name: 2944296@p-bc-5091
25/02/05 13:02:37 INFO SignalUtils: Registering signal handler for TERM
25/02/05 13:02:37 INFO SignalUtils: Registering signal handler for HUP
25/02/05 13:02:37 INFO SignalUtils: Registering signal handler for INT
25/02/05 13:02:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/05 13:02:37 INFO Utils: Successfully started service 'sparkWorker' on port 45403.
25/02/05 13:02:37 INFO Worker: Worker decommissioning not enabled.
25/02/05 13:02:37 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/02/05 13:02:37 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:37 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:37 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:37 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:37 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-bc-5038.2e.hpc.psu.edu:8081
25/02/05 13:02:37 INFO Worker: Connecting to master p-bc-5038:7077...
25/02/05 13:02:37 INFO TransportClientFactory: Successfully created connection to p-bc-5038/10.6.8.48:7077 after 39 ms (0 ms spent in bootstraps)
25/02/05 13:02:37 INFO Worker: Starting Spark worker 10.6.8.50:45403 with 1 cores, 15.0 GiB RAM
25/02/05 13:02:37 INFO Worker: Running Spark version 3.3.0
25/02/05 13:02:37 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/02/05 13:02:37 INFO ResourceUtils: ==============================================================
25/02/05 13:02:37 INFO ResourceUtils: No custom resources configured for spark.worker.
25/02/05 13:02:37 INFO ResourceUtils: ==============================================================
25/02/05 13:02:37 INFO Worker: Successfully registered with master spark://p-bc-5038:7077
25/02/05 13:02:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/05 13:02:37 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/02/05 13:02:38 INFO Utils: Successfully started service 'sparkWorker' on port 45535.
25/02/05 13:02:38 INFO Worker: Worker decommissioning not enabled.
25/02/05 13:02:38 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-bc-5040.2e.hpc.psu.edu:8081
25/02/05 13:02:38 INFO Worker: Connecting to master p-bc-5038:7077...
25/02/05 13:02:38 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:38 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:38 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/05 13:02:38 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:38 INFO TransportClientFactory: Successfully created connection to p-bc-5038/10.6.8.48:7077 after 41 ms (0 ms spent in bootstraps)
25/02/05 13:02:38 INFO Worker: Successfully registered with master spark://p-bc-5038:7077
25/02/05 13:02:38 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:38 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:38 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:38 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:38 INFO Worker: Starting Spark worker 10.6.8.99:45535 with 1 cores, 15.0 GiB RAM
25/02/05 13:02:38 INFO Worker: Running Spark version 3.3.0
25/02/05 13:02:38 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/02/05 13:02:38 INFO ResourceUtils: ==============================================================
25/02/05 13:02:38 INFO ResourceUtils: No custom resources configured for spark.worker.
25/02/05 13:02:38 INFO ResourceUtils: ==============================================================
25/02/05 13:02:38 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/02/05 13:02:38 INFO Utils: Successfully started service 'sparkWorker' on port 36297.
25/02/05 13:02:38 INFO Worker: Worker decommissioning not enabled.
25/02/05 13:02:39 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-bc-5089.2e.hpc.psu.edu:8081
25/02/05 13:02:39 INFO Worker: Connecting to master p-bc-5038:7077...
25/02/05 13:02:39 INFO TransportClientFactory: Successfully created connection to p-bc-5038/10.6.8.48:7077 after 44 ms (0 ms spent in bootstraps)
25/02/05 13:02:39 INFO Utils: Successfully started service 'sparkWorker' on port 44271.
25/02/05 13:02:39 INFO Worker: Worker decommissioning not enabled.
25/02/05 13:02:39 INFO Worker: Successfully registered with master spark://p-bc-5038:7077
25/02/05 13:02:39 INFO Worker: Starting Spark worker 10.6.8.97:36297 with 1 cores, 15.0 GiB RAM
25/02/05 13:02:39 INFO Worker: Running Spark version 3.3.0
25/02/05 13:02:39 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/02/05 13:02:39 INFO ResourceUtils: ==============================================================
25/02/05 13:02:39 INFO ResourceUtils: No custom resources configured for spark.worker.
25/02/05 13:02:39 INFO ResourceUtils: ==============================================================
25/02/05 13:02:39 INFO Worker: Starting Spark worker 10.6.8.101:44271 with 1 cores, 15.0 GiB RAM
25/02/05 13:02:39 INFO Worker: Running Spark version 3.3.0
25/02/05 13:02:39 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/02/05 13:02:39 INFO ResourceUtils: ==============================================================
25/02/05 13:02:39 INFO ResourceUtils: No custom resources configured for spark.worker.
25/02/05 13:02:39 INFO ResourceUtils: ==============================================================
25/02/05 13:02:40 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/02/05 13:02:40 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-bc-5087.2e.hpc.psu.edu:8081
25/02/05 13:02:40 INFO Worker: Connecting to master p-bc-5038:7077...
25/02/05 13:02:40 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/02/05 13:02:40 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-bc-5091.2e.hpc.psu.edu:8081
25/02/05 13:02:40 INFO Worker: Connecting to master p-bc-5038:7077...
25/02/05 13:02:40 INFO TransportClientFactory: Successfully created connection to p-bc-5038/10.6.8.48:7077 after 80 ms (0 ms spent in bootstraps)
25/02/05 13:02:40 INFO TransportClientFactory: Successfully created connection to p-bc-5038/10.6.8.48:7077 after 54 ms (0 ms spent in bootstraps)
25/02/05 13:02:40 INFO Worker: Successfully registered with master spark://p-bc-5038:7077
25/02/05 13:02:40 INFO Worker: Successfully registered with master spark://p-bc-5038:7077
25/02/05 13:02:54 INFO SparkContext: Running Spark version 3.3.0
25/02/05 13:02:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/05 13:02:55 INFO ResourceUtils: ==============================================================
25/02/05 13:02:55 INFO ResourceUtils: No custom resources configured for spark.driver.
25/02/05 13:02:55 INFO ResourceUtils: ==============================================================
25/02/05 13:02:55 INFO SparkContext: Submitted application: Lab4 BMB hastag changes
25/02/05 13:02:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/02/05 13:02:55 INFO ResourceProfile: Limiting resource is cpu
25/02/05 13:02:55 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/02/05 13:02:55 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:55 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:55 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:55 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:55 INFO Utils: Successfully started service 'sparkDriver' on port 33729.
25/02/05 13:02:55 INFO SparkEnv: Registering MapOutputTracker
25/02/05 13:02:55 INFO SparkEnv: Registering BlockManagerMaster
25/02/05 13:02:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/02/05 13:02:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/02/05 13:02:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/02/05 13:02:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ad4f6ea6-b185-445a-96ec-e7d5193a53ba
25/02/05 13:02:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/02/05 13:02:55 INFO SparkEnv: Registering OutputCommitCoordinator
25/02/05 13:02:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/02/05 13:02:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://p-bc-5038:7077...
25/02/05 13:02:56 INFO TransportClientFactory: Successfully created connection to p-bc-5038/10.6.8.48:7077 after 31 ms (0 ms spent in bootstraps)
25/02/05 13:02:56 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250205130256-0000
25/02/05 13:02:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36319.
25/02/05 13:02:56 INFO NettyBlockTransferService: Server created on p-bc-5038.2e.hpc.psu.edu:36319
25/02/05 13:02:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/02/05 13:02:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, p-bc-5038.2e.hpc.psu.edu, 36319, None)
25/02/05 13:02:56 INFO BlockManagerMasterEndpoint: Registering block manager p-bc-5038.2e.hpc.psu.edu:36319 with 434.4 MiB RAM, BlockManagerId(driver, p-bc-5038.2e.hpc.psu.edu, 36319, None)
25/02/05 13:02:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, p-bc-5038.2e.hpc.psu.edu, 36319, None)
25/02/05 13:02:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250205130256-0000/0 on worker-20250205130237-10.6.8.50-45403 (10.6.8.50:45403) with 1 core(s)
25/02/05 13:02:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250205130256-0000/0 on hostPort 10.6.8.50:45403 with 1 core(s), 1024.0 MiB RAM
25/02/05 13:02:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250205130256-0000/1 on worker-20250205130236-10.6.8.48-33517 (10.6.8.48:33517) with 1 core(s)
25/02/05 13:02:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250205130256-0000/1 on hostPort 10.6.8.48:33517 with 1 core(s), 1024.0 MiB RAM
25/02/05 13:02:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250205130256-0000/2 on worker-20250205130238-10.6.8.97-36297 (10.6.8.97:36297) with 1 core(s)
25/02/05 13:02:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250205130256-0000/2 on hostPort 10.6.8.97:36297 with 1 core(s), 1024.0 MiB RAM
25/02/05 13:02:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250205130256-0000/3 on worker-20250205130239-10.6.8.101-44271 (10.6.8.101:44271) with 1 core(s)
25/02/05 13:02:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250205130256-0000/3 on hostPort 10.6.8.101:44271 with 1 core(s), 1024.0 MiB RAM
25/02/05 13:02:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250205130256-0000/4 on worker-20250205130238-10.6.8.99-45535 (10.6.8.99:45535) with 1 core(s)
25/02/05 13:02:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, p-bc-5038.2e.hpc.psu.edu, 36319, None)
25/02/05 13:02:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250205130256-0000/4 on hostPort 10.6.8.99:45535 with 1 core(s), 1024.0 MiB RAM
25/02/05 13:02:56 INFO Worker: Asked to launch executor app-20250205130256-0000/0 for Lab4 BMB hastag changes
25/02/05 13:02:56 INFO Worker: Asked to launch executor app-20250205130256-0000/4 for Lab4 BMB hastag changes
25/02/05 13:02:56 INFO Worker: Asked to launch executor app-20250205130256-0000/1 for Lab4 BMB hastag changes
25/02/05 13:02:56 INFO Worker: Asked to launch executor app-20250205130256-0000/2 for Lab4 BMB hastag changes
25/02/05 13:02:56 INFO Worker: Asked to launch executor app-20250205130256-0000/3 for Lab4 BMB hastag changes
25/02/05 13:02:56 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:56 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:56 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:56 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java" "-cp" "/storage/work/rbm5518/Lab4/conf:/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/jars/*" "-Xmx1024M" "-Dspark.driver.port=33729" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@p-bc-5038.2e.hpc.psu.edu:33729" "--executor-id" "0" "--hostname" "10.6.8.50" "--cores" "1" "--app-id" "app-20250205130256-0000" "--worker-url" "spark://Worker@10.6.8.50:45403"
25/02/05 13:02:56 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:56 INFO SecurityManager: Changing view acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls to: rbm5518
25/02/05 13:02:56 INFO SecurityManager: Changing view acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 13:02:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rbm5518); groups with view permissions: Set(); users  with modify permissions: Set(rbm5518); groups with modify permissions: Set()
25/02/05 13:02:56 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java" "-cp" "/storage/work/rbm5518/Lab4/conf:/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/jars/*" "-Xmx1024M" "-Dspark.driver.port=33729" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@p-bc-5038.2e.hpc.psu.edu:33729" "--executor-id" "4" "--hostname" "10.6.8.99" "--cores" "1" "--app-id" "app-20250205130256-0000" "--worker-url" "spark://Worker@10.6.8.99:45535"
25/02/05 13:02:56 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java" "-cp" "/storage/work/rbm5518/Lab4/conf:/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/jars/*" "-Xmx1024M" "-Dspark.driver.port=33729" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@p-bc-5038.2e.hpc.psu.edu:33729" "--executor-id" "1" "--hostname" "10.6.8.48" "--cores" "1" "--app-id" "app-20250205130256-0000" "--worker-url" "spark://Worker@10.6.8.48:33517"
25/02/05 13:02:56 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/02/05 13:02:56 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java" "-cp" "/storage/work/rbm5518/Lab4/conf:/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/jars/*" "-Xmx1024M" "-Dspark.driver.port=33729" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@p-bc-5038.2e.hpc.psu.edu:33729" "--executor-id" "2" "--hostname" "10.6.8.97" "--cores" "1" "--app-id" "app-20250205130256-0000" "--worker-url" "spark://Worker@10.6.8.97:36297"
25/02/05 13:02:56 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java" "-cp" "/storage/work/rbm5518/Lab4/conf:/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/jars/*" "-Xmx1024M" "-Dspark.driver.port=33729" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@p-bc-5038.2e.hpc.psu.edu:33729" "--executor-id" "3" "--hostname" "10.6.8.101" "--cores" "1" "--app-id" "app-20250205130256-0000" "--worker-url" "spark://Worker@10.6.8.101:44271"
25/02/05 13:03:37 INFO Worker: Asked to kill executor app-20250205130256-0000/4
25/02/05 13:03:37 INFO ExecutorRunner: Runner thread for executor app-20250205130256-0000/4 interrupted
25/02/05 13:03:37 INFO ExecutorRunner: Killing process!
25/02/05 13:03:37 INFO Worker: Asked to kill executor app-20250205130256-0000/3
25/02/05 13:03:37 INFO Worker: Asked to kill executor app-20250205130256-0000/1
25/02/05 13:03:37 INFO Worker: Asked to kill executor app-20250205130256-0000/0
25/02/05 13:03:37 INFO Worker: Asked to kill executor app-20250205130256-0000/2
25/02/05 13:03:37 INFO ExecutorRunner: Runner thread for executor app-20250205130256-0000/0 interrupted
25/02/05 13:03:37 INFO ExecutorRunner: Killing process!
25/02/05 13:03:37 INFO ExecutorRunner: Runner thread for executor app-20250205130256-0000/3 interrupted
25/02/05 13:03:37 INFO ExecutorRunner: Killing process!
25/02/05 13:03:37 INFO ExecutorRunner: Runner thread for executor app-20250205130256-0000/1 interrupted
25/02/05 13:03:37 INFO ExecutorRunner: Runner thread for executor app-20250205130256-0000/2 interrupted
25/02/05 13:03:37 INFO ExecutorRunner: Killing process!
25/02/05 13:03:37 INFO ExecutorRunner: Killing process!
25/02/05 13:03:37 INFO Worker: Executor app-20250205130256-0000/0 finished with state KILLED exitStatus 143
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250205130256-0000, execId=0)
25/02/05 13:03:37 INFO Worker: Executor app-20250205130256-0000/4 finished with state KILLED exitStatus 143
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 4
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250205130256-0000, execId=4)
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Application app-20250205130256-0000 removed, cleanupLocalDirs = true
25/02/05 13:03:37 INFO Worker: Cleaning up local directories for application app-20250205130256-0000
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Application app-20250205130256-0000 removed, cleanupLocalDirs = true
25/02/05 13:03:37 INFO Worker: Cleaning up local directories for application app-20250205130256-0000
25/02/05 13:03:37 INFO Worker: Executor app-20250205130256-0000/1 finished with state KILLED exitStatus 143
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 1
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250205130256-0000, execId=1)
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Application app-20250205130256-0000 removed, cleanupLocalDirs = true
25/02/05 13:03:37 INFO Worker: Cleaning up local directories for application app-20250205130256-0000
25/02/05 13:03:37 INFO Worker: Executor app-20250205130256-0000/3 finished with state KILLED exitStatus 143
25/02/05 13:03:37 INFO Worker: Executor app-20250205130256-0000/2 finished with state KILLED exitStatus 143
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250205130256-0000, execId=2)
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 3
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250205130256-0000, execId=3)
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Application app-20250205130256-0000 removed, cleanupLocalDirs = true
25/02/05 13:03:37 INFO Worker: Cleaning up local directories for application app-20250205130256-0000
25/02/05 13:03:37 INFO ExternalShuffleBlockResolver: Application app-20250205130256-0000 removed, cleanupLocalDirs = true
25/02/05 13:03:37 INFO Worker: Cleaning up local directories for application app-20250205130256-0000
SPARK_MASTER_HOST=p-bc-5038
SPARK_MASTER_PORT=7077

real	1m14.165s
user	0m23.742s
sys	0m1.534s
slurmstepd: error: *** STEP 32121547.0 ON p-bc-5038 CANCELLED AT 2025-02-05T14:00:46 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
25/02/05 14:00:46 ERROR Worker: RECEIVED SIGNAL TERM
25/02/05 14:00:46 ERROR Worker: RECEIVED SIGNAL TERM
25/02/05 14:00:46 ERROR Worker: RECEIVED SIGNAL TERM
25/02/05 14:00:46 ERROR Worker: RECEIVED SIGNAL TERM
25/02/05 14:00:46 ERROR Worker: RECEIVED SIGNAL TERM
25/02/05 14:00:46 INFO ShutdownHookManager: Shutdown hook called
